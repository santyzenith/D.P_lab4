{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XHtaPysVSNZN"
   },
   "source": [
    "# Step 1 - Install the required dependencies and make sure the python version is 3.10 and above"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "APS6D3eiSAR_"
   },
   "source": [
    "!pip install zenoml"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!pip install datasets\n",
    "!pip install transformers\n",
    "!pip install tqdm\n",
    "!pip install torch"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CRrMiMnLV9xY",
    "outputId": "5193e819-f2cb-4032-99df-ced1ea7b4191",
    "scrolled": true
   },
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 - Load a dataset from Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@user @user what do these '1/2 naked pics' hav...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OH: “I had a blue penis while I was this” [pla...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@user @user That's coming, but I think the vic...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I think I may be finally in with the in crowd ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@user Wow,first Hugo Chavez and now Fidel Cast...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  @user @user what do these '1/2 naked pics' hav...      1\n",
       "1  OH: “I had a blue penis while I was this” [pla...      1\n",
       "2  @user @user That's coming, but I think the vic...      1\n",
       "3  I think I may be finally in with the in crowd ...      2\n",
       "4  @user Wow,first Hugo Chavez and now Fidel Cast...      0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "ds = load_dataset(\"cardiffnlp/tweet_eval\", \"sentiment\")\n",
    "df = pd.DataFrame(ds['test']).head(500)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_map(x):\n",
    "    if x == 0:\n",
    "        return 'negative'\n",
    "    elif x == 1:\n",
    "        return 'neutral'\n",
    "    elif x == 2:\n",
    "        return 'positive'\n",
    "    return x\n",
    "df['label'] = df['label'].map(label_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3 - Run model inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Warning: This step is going to download two models of ~500MB each. \n",
    "\n",
    "**If you don't want to download the models, you can jump to step 4 and use the provided data in the repo instead.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run inference with roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-classification\", \n",
    "                model=\"cardiffnlp/twitter-roberta-base-sentiment-latest\",\n",
    "                model_kwargs={\"device_map\":0}\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset                           | 7/500 [00:01<00:57,  8.59it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:08<00:00, 62.12it/s]\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "\n",
    "results = []\n",
    "texts = df['text'].to_list()\n",
    "\n",
    "## Depending on your machine, this should take around 1 minute\n",
    "for text in tqdm.tqdm(texts):\n",
    "    results.append(pipe(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['roberta'] = [r[0]['label'] for r in results]\n",
    "df['roberta_score'] = [r[0]['score'] for r in results]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run inference with gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-classification\", \n",
    "                model=\"LYTinn/finetuning-sentiment-model-tweet-gpt2\",\n",
    "                model_kwargs={\"device_map\": 0}\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:07<00:00, 69.19it/s]\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "\n",
    "results = []\n",
    "texts = df['text'].to_list()\n",
    "\n",
    "## Depending on your machine, this should take around 1 minute\n",
    "for text in tqdm.tqdm(texts):\n",
    "    results.append(pipe(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gpt2'] = [r[0]['label'] for r in results]\n",
    "df['gpt2_score'] = [r[0]['score'] for r in results]\n",
    "\n",
    "## map labels back\n",
    "def label_map(x):\n",
    "    if x == 'LABEL_0':\n",
    "        return 'negative'\n",
    "    elif x == 'LABEL_1':\n",
    "        return 'neutral'\n",
    "    elif x == 'LABEL_2':\n",
    "        return 'positive'\n",
    "    return x\n",
    "df['gpt2'] = df['gpt2'].map(label_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4 - Pre-processing data and add additional columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## If you skip the model inference, uncomment the code below and load the provided data\n",
    "\n",
    "# df = pd.read_csv('tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"input_length\"] = df[\"text\"].str.len()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5 - Start Zeno for interactive slicing\n",
    "\n",
    "In this step, you need to create 5 slices in the Zeno interface and derive meaningful insights.\n",
    "\n",
    "As a starting point, try to create the two slices we provide:\n",
    "\n",
    "1. Tweets with hashtags\n",
    "2. Tweets with strong positive words (e.g., love) -- you can determine the exact words"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating slices in Zeno is straightforward: Just click on the '+' button for 'create a new slice', and you can define the slice using existing column attributes, with simple value macthing or even regular expression.\n",
    "\n",
    "![image.png](images/image.png)\n",
    "\n",
    "There are more fun features in Zeno, including interactive metadata & model comparison -- feel free to check the teaser video in [README](https://github.com/zeno-ml/zeno) of the Zeno repository."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## Execute the code here to start a local Zeno server\n",
    "\n",
    "from zeno import zeno\n",
    "\n",
    "from zeno.api import model, distill, metric\n",
    "from zeno.api import ModelReturn, MetricReturn, DistillReturn, ZenoOptions\n",
    "\n",
    "@model\n",
    "def load_model(model_name):\n",
    "    \n",
    "    def pred(df, ops: ZenoOptions):\n",
    "        out = df[model_name]\n",
    "        return ModelReturn(model_output=out)\n",
    "\n",
    "    return pred\n",
    "\n",
    "@distill\n",
    "def label_match(df, ops: ZenoOptions):\n",
    "    results = (df[ops.label_column] == df[ops.output_column]).to_list()\n",
    "    return DistillReturn(distill_output=results)\n",
    "\n",
    "@metric\n",
    "def accuracy(df, ops: ZenoOptions):\n",
    "    avg = df[ops.distill_columns[\"label_match\"]].mean()\n",
    "    return MetricReturn(metric=avg)\n",
    "\n",
    "zeno({\n",
    "    \"metadata\": df, # Pandas DataFrame with a row for each instance\n",
    "    \"view\": \"text-classification\", # The type of view for this data/task\n",
    "    \"data_column\": \"text\", \n",
    "    \"label_column\": \"label\",\n",
    "    \"functions\": [load_model, label_match, accuracy],\n",
    "    \"models\": [\"roberta\", \"gpt2\"],\n",
    "    \"port\": 8231\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"index\"] = df.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully updated project.\n",
      "Access your project at  https://hub.zenoml.com/project/b31de552-b483-4cd1-9f97-b551531039a0/V2_Tweet%20Sentiment%20Analysis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\santy\\miniconda3\\envs\\desp_ia\\lib\\site-packages\\zeno_client\\util.py:25: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['0' '1' '2' '3' '4' '5' '6' '7' '8' '9' '10' '11' '12' '13' '14' '15'\n",
      " '16' '17' '18' '19' '20' '21' '22' '23' '24' '25' '26' '27' '28' '29'\n",
      " '30' '31' '32' '33' '34' '35' '36' '37' '38' '39' '40' '41' '42' '43'\n",
      " '44' '45' '46' '47' '48' '49' '50' '51' '52' '53' '54' '55' '56' '57'\n",
      " '58' '59' '60' '61' '62' '63' '64' '65' '66' '67' '68' '69' '70' '71'\n",
      " '72' '73' '74' '75' '76' '77' '78' '79' '80' '81' '82' '83' '84' '85'\n",
      " '86' '87' '88' '89' '90' '91' '92' '93' '94' '95' '96' '97' '98' '99'\n",
      " '100' '101' '102' '103' '104' '105' '106' '107' '108' '109' '110' '111'\n",
      " '112' '113' '114' '115' '116' '117' '118' '119' '120' '121' '122' '123'\n",
      " '124' '125' '126' '127' '128' '129' '130' '131' '132' '133' '134' '135'\n",
      " '136' '137' '138' '139' '140' '141' '142' '143' '144' '145' '146' '147'\n",
      " '148' '149' '150' '151' '152' '153' '154' '155' '156' '157' '158' '159'\n",
      " '160' '161' '162' '163' '164' '165' '166' '167' '168' '169' '170' '171'\n",
      " '172' '173' '174' '175' '176' '177' '178' '179' '180' '181' '182' '183'\n",
      " '184' '185' '186' '187' '188' '189' '190' '191' '192' '193' '194' '195'\n",
      " '196' '197' '198' '199' '200' '201' '202' '203' '204' '205' '206' '207'\n",
      " '208' '209' '210' '211' '212' '213' '214' '215' '216' '217' '218' '219'\n",
      " '220' '221' '222' '223' '224' '225' '226' '227' '228' '229' '230' '231'\n",
      " '232' '233' '234' '235' '236' '237' '238' '239' '240' '241' '242' '243'\n",
      " '244' '245' '246' '247' '248' '249' '250' '251' '252' '253' '254' '255'\n",
      " '256' '257' '258' '259' '260' '261' '262' '263' '264' '265' '266' '267'\n",
      " '268' '269' '270' '271' '272' '273' '274' '275' '276' '277' '278' '279'\n",
      " '280' '281' '282' '283' '284' '285' '286' '287' '288' '289' '290' '291'\n",
      " '292' '293' '294' '295' '296' '297' '298' '299' '300' '301' '302' '303'\n",
      " '304' '305' '306' '307' '308' '309' '310' '311' '312' '313' '314' '315'\n",
      " '316' '317' '318' '319' '320' '321' '322' '323' '324' '325' '326' '327'\n",
      " '328' '329' '330' '331' '332' '333' '334' '335' '336' '337' '338' '339'\n",
      " '340' '341' '342' '343' '344' '345' '346' '347' '348' '349' '350' '351'\n",
      " '352' '353' '354' '355' '356' '357' '358' '359' '360' '361' '362' '363'\n",
      " '364' '365' '366' '367' '368' '369' '370' '371' '372' '373' '374' '375'\n",
      " '376' '377' '378' '379' '380' '381' '382' '383' '384' '385' '386' '387'\n",
      " '388' '389' '390' '391' '392' '393' '394' '395' '396' '397' '398' '399'\n",
      " '400' '401' '402' '403' '404' '405' '406' '407' '408' '409' '410' '411'\n",
      " '412' '413' '414' '415' '416' '417' '418' '419' '420' '421' '422' '423'\n",
      " '424' '425' '426' '427' '428' '429' '430' '431' '432' '433' '434' '435'\n",
      " '436' '437' '438' '439' '440' '441' '442' '443' '444' '445' '446' '447'\n",
      " '448' '449' '450' '451' '452' '453' '454' '455' '456' '457' '458' '459'\n",
      " '460' '461' '462' '463' '464' '465' '466' '467' '468' '469' '470' '471'\n",
      " '472' '473' '474' '475' '476' '477' '478' '479' '480' '481' '482' '483'\n",
      " '484' '485' '486' '487' '488' '489' '490' '491' '492' '493' '494' '495'\n",
      " '496' '497' '498' '499']' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[:, id_column] = df[id_column].astype(str)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a65295cbe5e455fb1629aa3774e586b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully uploaded data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\santy\\AppData\\Local\\Temp\\ipykernel_17076\\1564226634.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_system[\"correct\"] = (df_system[model] == df[\"label\"]).astype(int)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a92cb1fd31b4716bf466080a220a571",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully uploaded system\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\santy\\AppData\\Local\\Temp\\ipykernel_17076\\1564226634.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_system[\"correct\"] = (df_system[model] == df[\"label\"]).astype(int)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d616c13f6bff471c82ad93ceb3030b14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully uploaded system\n"
     ]
    }
   ],
   "source": [
    "## If you don't have a Zeno account already, create one on Zeno Hub (https://hub.zenoml.com/signup). \n",
    "## After logging in to Zeno Hub, generate your API key by clicking on your profile at the top right to navigate to your account page.\n",
    "\n",
    "# !pip install zeno_client\n",
    "from zeno_client import ZenoClient, ZenoMetric\n",
    "import pandas as pd\n",
    "\n",
    "# df = pd.read_csv('tweets.csv')\n",
    "# df = df.reset_index()\n",
    "\n",
    "# Initialize a client with the API key.\n",
    "client = ZenoClient(\"your_key\")\n",
    "\n",
    "project = client.create_project(\n",
    "    name=\"V2_Tweet Sentiment Analysis\",\n",
    "    view=\"text-classification\",\n",
    "    metrics=[\n",
    "        ZenoMetric(name=\"accuracy\", type=\"mean\", columns=[\"correct\"]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "project.upload_dataset(df, id_column=\"index\", data_column=\"text\", label_column=\"label\")\n",
    "\n",
    "models = ['roberta', 'gpt2']\n",
    "for model in models:\n",
    "    df_system = df[['index', model]]\n",
    "    \n",
    "    # Measure accuracy for each instance, which is averaged by the ZenoMetric above\n",
    "    df_system[\"correct\"] = (df_system[model] == df[\"label\"]).astype(int)\n",
    "    \n",
    "    project.upload_system(df_system, name=model, id_column=\"index\", output_column=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>roberta</th>\n",
       "      <th>roberta_score</th>\n",
       "      <th>gpt2</th>\n",
       "      <th>gpt2_score</th>\n",
       "      <th>input_length</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@user @user what do these '1/2 naked pics' hav...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.804726</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.913452</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OH: “I had a blue penis while I was this” [pla...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.866949</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.753407</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@user @user That's coming, but I think the vic...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.763724</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>87</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I think I may be finally in with the in crowd ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.774047</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.898783</td>\n",
       "      <td>83</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@user Wow,first Hugo Chavez and now Fidel Cast...</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.416397</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.986431</td>\n",
       "      <td>133</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>Donnie is gonna deport the Menendez Brothers r...</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.915344</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.999632</td>\n",
       "      <td>69</td>\n",
       "      <td>495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>Still reading #SettleForMore @user #fridayreads</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.797208</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.999972</td>\n",
       "      <td>47</td>\n",
       "      <td>496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>#Chocolate cupcake #candle melting with its sw...</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.951857</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.999672</td>\n",
       "      <td>96</td>\n",
       "      <td>497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>Is this leaf ?Can I eat ?Open the leaf!Oh! Thi...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.664862</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.999548</td>\n",
       "      <td>101</td>\n",
       "      <td>498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>\"We have lost everything\": Syrians return to r...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.751955</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.994244</td>\n",
       "      <td>92</td>\n",
       "      <td>499</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text     label   roberta  \\\n",
       "0    @user @user what do these '1/2 naked pics' hav...   neutral  negative   \n",
       "1    OH: “I had a blue penis while I was this” [pla...   neutral   neutral   \n",
       "2    @user @user That's coming, but I think the vic...   neutral   neutral   \n",
       "3    I think I may be finally in with the in crowd ...  positive  positive   \n",
       "4    @user Wow,first Hugo Chavez and now Fidel Cast...  negative   neutral   \n",
       "..                                                 ...       ...       ...   \n",
       "495  Donnie is gonna deport the Menendez Brothers r...  negative  negative   \n",
       "496    Still reading #SettleForMore @user #fridayreads   neutral   neutral   \n",
       "497  #Chocolate cupcake #candle melting with its sw...  positive  positive   \n",
       "498  Is this leaf ?Can I eat ?Open the leaf!Oh! Thi...   neutral  positive   \n",
       "499  \"We have lost everything\": Syrians return to r...   neutral  negative   \n",
       "\n",
       "     roberta_score      gpt2  gpt2_score  input_length index  \n",
       "0         0.804726  positive    0.913452            96     0  \n",
       "1         0.866949   neutral    0.753407            72     1  \n",
       "2         0.763724  positive    0.999962            87     2  \n",
       "3         0.774047  positive    0.898783            83     3  \n",
       "4         0.416397  positive    0.986431           133     4  \n",
       "..             ...       ...         ...           ...   ...  \n",
       "495       0.915344   neutral    0.999632            69   495  \n",
       "496       0.797208  positive    0.999972            47   496  \n",
       "497       0.951857  negative    0.999672            96   497  \n",
       "498       0.664862  negative    0.999548           101   498  \n",
       "499       0.751955  positive    0.994244            92   499  \n",
       "\n",
       "[500 rows x 8 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running the code above, you should be able to access Zeno in http://localhost:8231"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "After successfully creating the two slices, come up with three *additional* slices you want to check and **create** the slices in the Zeno interface.\n",
    "\n",
    "There are two directions to identify useful slices:\n",
    "- Top-down: Think about what kinds of things the model can struggle with, and come up with some slices.\n",
    "- Bottom-up: Look at model (mis-)predictions, come up with hypotheses, and translate them into data slices.\n",
    "\n",
    "3. [YOUR CHOICE]\n",
    "4. [YOUR CHOICE]\n",
    "5. [YOUR CHOICE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write down descriptions of additional slices you created\n",
    "\n",
    "custom_slice_descriptions = [\n",
    "    \"\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6 - Write down three addition data slices you want to create but do not have the metadata for slicing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous step, you might have already come up with some slices you wanted to create but found it hard to do with existing metadata. Write down three of such slices in this step.\n",
    "\n",
    "Example: \n",
    "- I want to create a slice on tweets using slangs\n",
    "- I want to create a slice on non-English tweets (if any)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write down three additional data slices here:\n",
    "\n",
    "additional_slice_descriptions = [\n",
    "    \"\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7 - Generate more test cases with Large Language Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select one slice from the three you wrote down and generate **10 test cases** using LLMs, which can include average case, boundary case, or difficult case.\n",
    "\n",
    "Your input can be in the following format:\n",
    "\n",
    "> Examples:\n",
    "> - OH: “I had a blue penis while I was this” [playing with Google Earth VR]\n",
    "> - @user @user That’s coming, but I think the victims are going to be Medicaid recipients.\n",
    "> - I think I may be finally in with the in crowd #mannequinchallenge  #grads2014 @user\n",
    "> \n",
    "> Generate more tweets using slangs.\n",
    "\n",
    "The first part of **Examples** conditions the LLM on the style, length, and content of examples. The second part of **Instructions** instructs what kind of examples you want LLM to generate.\n",
    "\n",
    "Use our provided GPTs to start the task: [llm-based-test-case-generator](https://chatgpt.com/g/g-982cylVn2-llm-based-test-case-generator). If you do not have access to GPTs, use the plain ChatGPT or other LLM providers you have access to instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write down the slice you select\n",
    "\n",
    "slice_description = \"Tweets con violencia de género\"\n",
    "\n",
    "## Write down all generated test cases here\n",
    "\n",
    "generated_test_cases = [\n",
    "\"Women should know their place.\",\n",
    "\n",
    "\"She's just asking for it with the way she dresses.\",\n",
    "\n",
    "\"Why would a woman want to be in charge? She'll only make a mess.\",\n",
    "\n",
    "\"Girls are only good for looking pretty, not for serious work.\",\n",
    "\n",
    "\"A woman is only valuable when she’s quiet and obedient.\",\n",
    "\n",
    "\"She’s too emotional to make important decisions.\",\n",
    "\n",
    "\"Women are just drama queens who can't take a joke.\",\n",
    "\n",
    "\"Why do women always have to complain about everything?\",\n",
    "\n",
    "\"She was asking for trouble when she went out like that.\",\n",
    "\n",
    "\"It's hard to take a woman seriously when she's crying.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Women should know their place.',\n",
       " \"She's just asking for it with the way she dresses.\",\n",
       " \"Why would a woman want to be in charge? She'll only make a mess.\",\n",
       " 'Girls are only good for looking pretty, not for serious work.',\n",
       " 'A woman is only valuable when she’s quiet and obedient.',\n",
       " 'She’s too emotional to make important decisions.',\n",
       " \"Women are just drama queens who can't take a joke.\",\n",
       " 'Why do women always have to complain about everything?',\n",
       " 'She was asking for trouble when she went out like that.',\n",
       " \"It's hard to take a woman seriously when she's crying.\"]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_test_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nuevos = pd.DataFrame({'text': generated_test_cases})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 8 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   text           500 non-null    object \n",
      " 1   label          500 non-null    object \n",
      " 2   roberta        500 non-null    object \n",
      " 3   roberta_score  500 non-null    float64\n",
      " 4   gpt2           500 non-null    object \n",
      " 5   gpt2_score     500 non-null    float64\n",
      " 6   input_length   500 non-null    int64  \n",
      " 7   index          500 non-null    object \n",
      "dtypes: float64(2), int64(1), object(5)\n",
      "memory usage: 31.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
